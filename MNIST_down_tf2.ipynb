{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Reshape, Dense, Dropout, Flatten, LeakyReLU, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import PrivacyGAN as pg\n",
    "import warnings\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "#https://github.com/keras-team/keras/wiki/Keras-2.0-release-notes\n",
    "#https://stackoverflow.com/questions/60289143/migrating-code-to-tensorflow-2-0-gives-invalid-argument-error-default-maxpoolin\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_test = (X_test.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate simple synthetic images of same size as X_train with same balance\n",
    "X_c = []\n",
    "y_c = []\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    print(i)\n",
    "    In = np.where(y_train==i)\n",
    "    X = X_train[In]\n",
    "    tf.keras.backend.clear_session()\n",
    "    optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    gen = pg.MNIST_Generator(optim=optim)\n",
    "    dis = pg.MNIST_Discriminator(optim=optim)\n",
    "    \n",
    "    #learn generator per digit \n",
    "    (generator, _, _, _) = pg.SimpGAN(X, generator = gen, discriminator = dis, \n",
    "                                      optim = optim, \n",
    "                                      epochs = 200, batchSize = 256)\n",
    "    \n",
    "    noise = np.random.normal(0, 1, size=[len(X), 100])\n",
    "    X_c += [generator.predict(noise)]\n",
    "    y_c += [i]*len(X)\n",
    "    \n",
    "X_c = np.concatenate(X_c)    \n",
    "y_c = np.array(y_c)\n",
    "\n",
    "\n",
    "## Shuffle labels around\n",
    "arr = np.arange(len(X_c))\n",
    "np.random.shuffle(arr)\n",
    "X_c = X_c[arr]\n",
    "y_c = y_c[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train CNN model\n",
    "tf.keras.backend.clear_session()\n",
    "tf.keras.utils.to_categorical\n",
    "y_tr = tf.keras.utils.to_categorical(y_c, NUM_CLASSES)\n",
    "y_t = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "\n",
    "\n",
    "x_train = X_c.reshape(X_c.shape[0], 28, 28, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), data_format = 'channels_last'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95, epsilon=1e-06),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_tr,\n",
    "          batch_size=256,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_t))\n",
    "score = model.evaluate(x_test, y_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification accuracy on test set\n",
    "score = model.evaluate(x_test, y_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "r_0 = [score[0],score[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train CNN model\n",
    "tf.keras.backend.clear_session()\n",
    "y_tr = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_t = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "x_train = X_train.reshape(X_c.shape[0], 28, 28, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# 10 classes so a dense layer of 10\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95, epsilon=1e-06),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_tr,\n",
    "          batch_size=256,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification accuracy on test set\n",
    "score = model.evaluate(x_test, y_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "r_1 = [score[0],score[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate simple synthetic images of same size as X_train with same balance\n",
    "X_c2 = []\n",
    "y_c2 = []\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    print(i)\n",
    "    In = np.where(y_train==i)\n",
    "    X = X_train[In]\n",
    "    tf.keras.backend.clear_session()\n",
    "    optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    generators = [pg.MNIST_Generator(optim = Adam(lr=0.0002, beta_1=0.5)),\n",
    "                  pg.MNIST_Generator(optim = Adam(lr=0.0002, beta_1=0.5))]\n",
    "    discriminators = [pg.MNIST_Discriminator(optim = Adam(lr=0.0002, beta_1=0.5))\n",
    "                      ,pg.MNIST_Discriminator(optim = Adam(lr=0.0002, beta_1=0.5))]\n",
    "    pDisc = pg.MNIST_DiscriminatorPrivate(OutSize = 2, \n",
    "                                          optim = Adam(lr=0.0002, beta_1=0.5))\n",
    "    \n",
    "    (generators, _, _, _, _, _)= pg.privGAN(X, epochs = 200, \n",
    "                                                                               disc_epochs=50,\n",
    "                                                                               batchSize=256,\n",
    "                                                                               generators = generators, \n",
    "                                                                               discriminators = discriminators,\n",
    "                                                                               pDisc = pDisc,\n",
    "                                                                               optim = optim,\n",
    "                                                                               privacy_ratio = 1.0)    \n",
    "    \n",
    "    noise1 = np.random.normal(0, 1, size=[len(X)//2, 100])\n",
    "    noise2 = np.random.normal(0, 1, size=[len(X)//2, 100])\n",
    "    X_c2 += [generators[0].predict(noise1)]\n",
    "    X_c2 += [generators[1].predict(noise2)]\n",
    "    y_c2 += [i]*(len(noise1) + len(noise2))\n",
    "    \n",
    "X_c2 = np.concatenate(X_c2)    \n",
    "y_c2 = np.array(y_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle labels around\n",
    "arr = np.arange(len(X_c2))\n",
    "np.random.shuffle(arr)\n",
    "X_c2 = X_c2[arr]\n",
    "y_c2 = y_c2[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train CNN model\n",
    "tf.keras.backend.clear_session()\n",
    "y_tr = tf.keras.utils.to_categorical(y_c2, NUM_CLASSES)\n",
    "y_t = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "x_train = X_c2.reshape(X_c2.shape[0], 28, 28, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95, epsilon=1e-06),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_tr,\n",
    "          batch_size=256,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "r_2 = [score[0],score[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([0,1,2],[r_1[1],r_0[1],r_2[1]])\n",
    "plt.xticks([0,1,2],['Real','GAN','privGAN (1.0)'], rotation=45)\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
